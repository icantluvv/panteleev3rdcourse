{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "nlp = spacy.load('ru_core_news_sm')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy[ru] in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (1.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (1.1.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (3.1.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (4.66.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (3.0.12)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (0.3.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (2.0.10)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (1.26.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (23.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (2.4.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (2.4.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (1.0.10)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (8.2.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (6.4.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (0.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy[ru]) (57.4.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[ru]) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[ru]) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[ru]) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[ru]) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[ru]) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[ru]) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[ru]) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy[ru]) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy[ru]) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy[ru]) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy[ru]) (8.1.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy[ru]) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\spant\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy[ru]) (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: spacy 3.7.2 does not provide the extra 'ru'\n",
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy[ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('banks.csv',sep =\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenizer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8658</th>\n",
       "      <td>Мне прискорбно заявлять,что некогда уважаемому...</td>\n",
       "      <td>[прискорбно, заявлять, уважаемому, Альфа, Банк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641</th>\n",
       "      <td>3 октября 2016 года после полудня (точное врем...</td>\n",
       "      <td>[3, октября, 2016, года, полудня, точное, врем...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7269</th>\n",
       "      <td>Была заказана карта Бинбанк Visa Platinum по а...</td>\n",
       "      <td>[заказана, карта, Бинбанк, Visa, Platinum, акц...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>Ну что я могу сказать?.. ТКС работает на 5+! П...</td>\n",
       "      <td>[сказать, ТКС, работает, 5, +, крайней, мере, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>Открыл рублевый дебетовый счет в Альфе,пользов...</td>\n",
       "      <td>[Открыл, рублевый, дебетовый, счет, Альфе, пол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>Уважаемый Альфа Банк,вот уже четвертый месяц в...</td>\n",
       "      <td>[Уважаемый, Альфа, Банк, четвертый, месяц, Сэб...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>Являюсь клиентом ПАО БИНБАНК. 24.04.2017 в 18 ...</td>\n",
       "      <td>[Являюсь, клиентом, ПАО, БИНБАНК, 24.04.2017, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143</th>\n",
       "      <td>Что же это такое творится,господа банкиры!?Два...</td>\n",
       "      <td>[творится, господа, банкиры!?Два, обращения, к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>Я устал и сил моральных общаться с банком нет ...</td>\n",
       "      <td>[устал, сил, моральных, общаться, банком, уйти...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>Добрый день! Являюсь московским клиентом банка...</td>\n",
       "      <td>[Добрый, день, Являюсь, московским, клиентом, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6998 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "8658  Мне прискорбно заявлять,что некогда уважаемому...   \n",
       "7641  3 октября 2016 года после полудня (точное врем...   \n",
       "7269  Была заказана карта Бинбанк Visa Platinum по а...   \n",
       "2688  Ну что я могу сказать?.. ТКС работает на 5+! П...   \n",
       "4917  Открыл рублевый дебетовый счет в Альфе,пользов...   \n",
       "...                                                 ...   \n",
       "3007  Уважаемый Альфа Банк,вот уже четвертый месяц в...   \n",
       "7148  Являюсь клиентом ПАО БИНБАНК. 24.04.2017 в 18 ...   \n",
       "9143  Что же это такое творится,господа банкиры!?Два...   \n",
       "1295  Я устал и сил моральных общаться с банком нет ...   \n",
       "5833  Добрый день! Являюсь московским клиентом банка...   \n",
       "\n",
       "                                         tokenizer_text  \n",
       "8658  [прискорбно, заявлять, уважаемому, Альфа, Банк...  \n",
       "7641  [3, октября, 2016, года, полудня, точное, врем...  \n",
       "7269  [заказана, карта, Бинбанк, Visa, Platinum, акц...  \n",
       "2688  [сказать, ТКС, работает, 5, +, крайней, мере, ...  \n",
       "4917  [Открыл, рублевый, дебетовый, счет, Альфе, пол...  \n",
       "...                                                 ...  \n",
       "3007  [Уважаемый, Альфа, Банк, четвертый, месяц, Сэб...  \n",
       "7148  [Являюсь, клиентом, ПАО, БИНБАНК, 24.04.2017, ...  \n",
       "9143  [творится, господа, банкиры!?Два, обращения, к...  \n",
       "1295  [устал, сил, моральных, общаться, банком, уйти...  \n",
       "5833  [Добрый, день, Являюсь, московским, клиентом, ...  \n",
       "\n",
       "[6998 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('ru_core_news_sm')\n",
    "    \n",
    "    def tokenize_text(self, text):\n",
    "        tokens = []\n",
    "        for sentence in self.nlp(text).sents:\n",
    "            for token in sentence:\n",
    "                if not token.is_stop and not token.is_punct:\n",
    "                    tokens.append(token.text)\n",
    "        return tokens\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Score'], test_size=0.5, random_state=35)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "new_data = pd.DataFrame({'text': X_train, 'tokenizer_text': X_train.apply(tokenizer.tokenize_text)})\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "data['Score'] = data['Score'].apply(lambda x: 1 if x == 'Positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Logistic Regression): 0.9387055293613373\n",
      "\n",
      "Classification Report (Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.93      0.95      0.94      3501\n",
      "    Positive       0.95      0.93      0.94      3498\n",
      "\n",
      "    accuracy                           0.94      6999\n",
      "   macro avg       0.94      0.94      0.94      6999\n",
      "weighted avg       0.94      0.94      0.94      6999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizer.tokenize_text)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "logistic_model = make_pipeline(LogisticRegression())\n",
    "logistic_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "y_pred_logistic = logistic_model.predict(X_test_vectorized)\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print('Accuracy (Logistic Regression):', accuracy_logistic)\n",
    "\n",
    "print('\\nClassification Report (Logistic Regression):\\n', classification_report(y_test, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\spant\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "# использование НС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Score'], test_size=0.5, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_tokenized = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokenized = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = pad_sequences(X_train_tokenized)\n",
    "X_test_padded = pad_sequences(X_test_tokenized, maxlen=X_train_padded.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\spant\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\spant\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(tokenizer.word_index)+1, 100, input_length=X_train_padded.shape[1]),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "219/219 [==============================] - 69s 314ms/step - loss: 0.3212 - accuracy: 0.8818\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 71s 323ms/step - loss: 0.1057 - accuracy: 0.9650\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 71s 325ms/step - loss: 0.0251 - accuracy: 0.9961\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 72s 329ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 73s 332ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 74s 337ms/step - loss: 9.9274e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 74s 337ms/step - loss: 6.4537e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 73s 335ms/step - loss: 4.5065e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 73s 333ms/step - loss: 3.2948e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 73s 333ms/step - loss: 2.4854e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x223b2866380>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_padded, y_train_encoded, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 9s 42ms/step - loss: 0.2319 - accuracy: 0.9363\n",
      "Accuracy: 93.6\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test_padded, y_test_encoded)\n",
    "print('Accuracy: %.1f' % (accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
